{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train the model for a Q&A task that takes a context as addi'onal input along with the queston. You can use SQuAD dataset (ttps://rajpurkar.github.io/SQuAD-explorer/ ) or the smaller Topioca dataset (https://## mcgill-nlp.github.io/topiocqa/) . Choose an appropriate task prefix/trigger word and jus'fy the choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "#dataset = load_dataset(\"squad\", data_files=\"/Users/prabhatkumar/Downloads/train-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def apply_dataframe(row):\n",
    "    df = pd.DataFrame(row['paragraphs'])\n",
    "    df['title'] = row['title']\n",
    "    return df\n",
    "\n",
    "def apply_dataframe1(row):\n",
    "    #print(row['qas'])\n",
    "    if 'plausible_answers' in row['qas']:\n",
    "        row['qas']['answers'] = row['qas']['plausible_answers']\n",
    "        del row['qas']['plausible_answers']\n",
    "    df = pd.DataFrame(row['qas'])\n",
    "    df['title'] = row['title']\n",
    "    df['context'] = row['context']\n",
    "    \n",
    "    return df\n",
    "        \n",
    "\n",
    "train = pd.read_json(\"/Users/prabhatkumar/Downloads/train-v2.0.json\")\n",
    "valid = pd.read_json(\"/Users/prabhatkumar/Downloads/dev-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_json(df):\n",
    "    df['text1'] = df['data'].apply(pd.DataFrame)\n",
    "    df = pd.concat(df['text1'].tolist())\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['text1'] = df.apply(apply_dataframe,axis=1)\n",
    "    df = pd.concat(df['text1'].tolist())\n",
    "    df['text1'] = df.apply(apply_dataframe1,axis=1)\n",
    "    df['text2'] = df['text1'].apply(lambda x : len(x.columns.tolist()))\n",
    "    df = pd.concat(df['text1'].tolist())\n",
    "    df['answer'] = df['answers'].apply(lambda x: x['text'])\n",
    "\n",
    "    df=df[['id','title','question','context','answer']]\n",
    "    df = df.drop_duplicates()\n",
    "    df=df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =create_df_from_json(train)\n",
    "valid =create_df_from_json(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9065  Beyoncé   \n",
       "2  56be85543aeaaa14008c9066  Beyoncé   \n",
       "3  56bf6b0f3aeaaa14008c9601  Beyoncé   \n",
       "4  56bf6b0f3aeaaa14008c9602  Beyoncé   \n",
       "\n",
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context               answer  \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s  \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing  \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003  \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas  \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>in the 10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56ddde6b9a695914005b962a</td>\n",
       "      <td>Normans</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56ddde6b9a695914005b962b</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56ddde6b9a695914005b9628  Normans   \n",
       "1  56ddde6b9a695914005b9629  Normans   \n",
       "2  56ddde6b9a695914005b9629  Normans   \n",
       "3  56ddde6b9a695914005b962a  Normans   \n",
       "4  56ddde6b9a695914005b962b  Normans   \n",
       "\n",
       "                                        question  \\\n",
       "0           In what country is Normandy located?   \n",
       "1             When were the Normans in Normandy?   \n",
       "2             When were the Normans in Normandy?   \n",
       "3  From which countries did the Norse originate?   \n",
       "4                      Who was the Norse leader?   \n",
       "\n",
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "3  The Normans (Norman: Nourmands; French: Norman...   \n",
       "4  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                           answer  \n",
       "0                          France  \n",
       "1         10th and 11th centuries  \n",
       "2  in the 10th and 11th centuries  \n",
       "3     Denmark, Iceland and Norway  \n",
       "4                           Rollo  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[0:3500]\n",
    "valid = valid.loc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "valid_dataset = Dataset.from_pandas(valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selected question: question context: context because the model T5 FLAN is already trained on this pattern for question answer so providing this template/prompt as examples for training. We could have tried other template if we are including domain question awnser. ALso model has been fully trained for all layers instead of finetuning a few layers because the data is huge. The ideal way is to train all layers for few epochs then freeze all layers expect the head or few layers of decoder and encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook I had to use only sample of data to train since colab was going timeout and I dont have a GPU powered laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
    "    targets = examples[\"answer\"]\n",
    "    #print(inputs)\n",
    "    #print(targets)\n",
    "    #inputs = tokenizer(inputs, padding=True, truncation=True,return_tensors=\"pt\")\n",
    "    #targets = tokenizer(targets, padding=True, truncation=True,return_tensors=\"pt\")\n",
    "    inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=512,return_tensors=\"pt\")\n",
    "    targets = tokenizer(targets, padding='max_length', truncation=True, max_length=512,return_tensors=\"pt\")\n",
    "    \n",
    "    return {\n",
    "        'input_ids': inputs.input_ids,\n",
    "        'attention_mask': inputs.attention_mask,\n",
    "        'decoder_input_ids': targets.input_ids,\n",
    "        'labels': targets.input_ids,\n",
    "    }\n",
    "\n",
    "    #return {\"input_ids\": tokenizer(inputs, padding=\"max_length\", max_length=64, truncation=True), \"labels\": tokenizer(targets, padding=\"max_length\", max_length=32, truncation=True)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e132a989cd9e4483bdf14649d79e1ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3501 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8848868d51ed48afacbef90789722b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "from transformers.utils import PaddingStrategy\n",
    "import numpy as np\n",
    "@dataclass\n",
    "class CustomDataCollatorForSeq2Seq:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        model ([`PreTrainedModel`]):\n",
    "            The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n",
    "            prepare the *decoder_input_ids*\n",
    "\n",
    "            This is useful when using *label_smoothing* to avoid calculating loss twice.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        label_pad_token_id (`int`, *optional*, defaults to -100):\n",
    "            The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    model: Optional[Any] = None\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        if return_tensors is None:\n",
    "            return_tensors = self.return_tensors\n",
    "        labels = [feature[\"labels\"] for feature in features] if \"labels\" in features[0].keys() else None\n",
    "        \n",
    "        # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n",
    "        # same length to return tensors.\n",
    "        if labels is not None:\n",
    "            max_label_length = max(len(l) for l in labels)\n",
    "            if self.pad_to_multiple_of is not None:\n",
    "                max_label_length = (\n",
    "                    (max_label_length + self.pad_to_multiple_of - 1)\n",
    "                    // self.pad_to_multiple_of\n",
    "                    * self.pad_to_multiple_of\n",
    "                )\n",
    "\n",
    "            padding_side = self.tokenizer.padding_side\n",
    "            for feature in features:\n",
    "                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n",
    "                if isinstance(feature[\"labels\"], list):\n",
    "                    feature[\"labels\"] = (\n",
    "                        feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n",
    "                    )\n",
    "                elif padding_side == \"right\":\n",
    "                    feature[\"labels\"] = np.concatenate([feature[\"labels\"], remainder]).astype(np.int64)\n",
    "                else:\n",
    "                    feature[\"labels\"] = np.concatenate([remainder, feature[\"labels\"]]).astype(np.int64)\n",
    "\n",
    "        features = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=return_tensors,\n",
    "        )\n",
    "        print(features)\n",
    "        # prepare decoder_input_ids\n",
    "        if (\n",
    "            labels is not None\n",
    "            and self.model is not None\n",
    "            and hasattr(self.model, \"prepare_decoder_input_ids_from_labels\")\n",
    "        ):\n",
    "            decoder_input_ids = self.model.prepare_decoder_input_ids_from_labels(labels=features[\"labels\"])\n",
    "            features[\"decoder_input_ids\"] = decoder_input_ids\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9065  Beyoncé   \n",
       "2  56be85543aeaaa14008c9066  Beyoncé   \n",
       "3  56bf6b0f3aeaaa14008c9601  Beyoncé   \n",
       "4  56bf6b0f3aeaaa14008c9602  Beyoncé   \n",
       "\n",
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context               answer  \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s  \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing  \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003  \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas  \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-question-answering\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_steps=10000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=2000,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d161c00007584e538d6d728f79488cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2356, 'learning_rate': 1.1948249619482495e-05, 'epoch': 2.28}\n",
      "{'train_runtime': 23722.254, 'train_samples_per_second': 0.443, 'train_steps_per_second': 0.028, 'train_loss': 1.7246996169765245, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=657, training_loss=1.7246996169765245, metrics={'train_runtime': 23722.254, 'train_samples_per_second': 0.443, 'train_steps_per_second': 0.028, 'train_loss': 1.7246996169765245, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d452c2e6506246a1bfd1b4e5b7699c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.027084223926067352,\n",
       " 'eval_runtime': 484.0654,\n",
       " 'eval_samples_per_second': 2.068,\n",
       " 'eval_steps_per_second': 0.13,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./t5-question-answering-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = T5ForConditionalGeneration.from_pretrained(\"./t5-question-answering-finetuned\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '75-year-old'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model_new,tokenizer=tokenizer)\n",
    "text=\"question: What is the age of Greg chappel? context: Cricket legend Greg Chappell has revealed going through a financial struggle with his friends pitching in to set up an online fundraising platform to enhance his last few years, according to a report. The 75-year-old former Australia captain, who also had a controversial stint as the head coach of the Indian team from 2005-2007, admitted that he is doing fine but is certainly not living a life of luxury as a result of his cricketing career.\"\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluate the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pd.read_json(\"/Users/prabhatkumar/Downloads/dev-v2.0.json\")\n",
    "eval =create_df_from_json(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = eval[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5ad26c87d7d075001a42939c</td>\n",
       "      <td>Huguenot</td>\n",
       "      <td>Which English town had the largest refugee chu...</td>\n",
       "      <td>Other evidence of the Walloons and Huguenots i...</td>\n",
       "      <td>Canterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>57109180a58dae1900cd6a40</td>\n",
       "      <td>Huguenot</td>\n",
       "      <td>What Irish cities had Huguenot mayors in the 1...</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Dublin, Cork, Youghal and Waterford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>57109180a58dae1900cd6a41</td>\n",
       "      <td>Huguenot</td>\n",
       "      <td>French Church Street is in what Irish town?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Cork City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>57109180a58dae1900cd6a42</td>\n",
       "      <td>Huguenot</td>\n",
       "      <td>Where is D'Olier Street?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>57109180a58dae1900cd6a43</td>\n",
       "      <td>Huguenot</td>\n",
       "      <td>D'Olier Street is named after whom?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>a High Sheriff and one of the founders of the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id     title  \\\n",
       "2000  5ad26c87d7d075001a42939c  Huguenot   \n",
       "2001  57109180a58dae1900cd6a40  Huguenot   \n",
       "2002  57109180a58dae1900cd6a41  Huguenot   \n",
       "2003  57109180a58dae1900cd6a42  Huguenot   \n",
       "2004  57109180a58dae1900cd6a43  Huguenot   \n",
       "\n",
       "                                               question  \\\n",
       "2000  Which English town had the largest refugee chu...   \n",
       "2001  What Irish cities had Huguenot mayors in the 1...   \n",
       "2002        French Church Street is in what Irish town?   \n",
       "2003                           Where is D'Olier Street?   \n",
       "2004                D'Olier Street is named after whom?   \n",
       "\n",
       "                                                context  \\\n",
       "2000  Other evidence of the Walloons and Huguenots i...   \n",
       "2001  A number of Huguenots served as mayors in Dubl...   \n",
       "2002  A number of Huguenots served as mayors in Dubl...   \n",
       "2003  A number of Huguenots served as mayors in Dubl...   \n",
       "2004  A number of Huguenots served as mayors in Dubl...   \n",
       "\n",
       "                                                 answer  \n",
       "2000                                         Canterbury  \n",
       "2001                Dublin, Cork, Youghal and Waterford  \n",
       "2002                                          Cork City  \n",
       "2003                                             Dublin  \n",
       "2004  a High Sheriff and one of the founders of the ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = eval['question'].tolist()\n",
    "context = eval['context'].tolist()\n",
    "actual_answer = eval['answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answers=[]\n",
    "for q,c in zip(questions,context):\n",
    "    text=f\"question: {q} context: {c}\"\n",
    "    pred_answers.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer_mod = [col[0]['generated_text'] for col  in pred_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def answer_evaluation(actual_answer, predicted_answer,threshold=0.9):\n",
    "    actual_answer = actual_answer.lower()  \n",
    "    predicted_answer = predicted_answer.lower()\n",
    "\n",
    "    similarity = difflib.SequenceMatcher(None, actual_answer, predicted_answer).ratio()\n",
    "\n",
    "    if similarity >= threshold:\n",
    "        return \"Exact Match\"\n",
    "    elif similarity >= 0.7:\n",
    "        return \"High Partial Match\"\n",
    "    elif similarity >= 0.4:\n",
    "        return \"Low Partial Match\"\n",
    "    else:\n",
    "        return \"No Match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "for act,pred in zip(actual_answer,pred_answer_mod):\n",
    "    #print(act,'....',pred)\n",
    "    response_list.append(answer_evaluation(act, pred,threshold=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame()\n",
    "eval_df['questions'] = questions\n",
    "eval_df['context'] = context\n",
    "eval_df['actual_answer'] = actual_answer\n",
    "eval_df['predicted_answer'] = pred_answer_mod\n",
    "eval_df['evaluation_criteria'] = response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>context</th>\n",
       "      <th>actual_answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>evaluation_criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which English town had the largest refugee chu...</td>\n",
       "      <td>Other evidence of the Walloons and Huguenots i...</td>\n",
       "      <td>Canterbury</td>\n",
       "      <td>Sandwich, Faversham and Maidstone</td>\n",
       "      <td>No Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Irish cities had Huguenot mayors in the 1...</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Dublin, Cork, Youghal and Waterford</td>\n",
       "      <td>Dublin, Cork, Youghal and Waterford</td>\n",
       "      <td>Exact Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French Church Street is in what Irish town?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Cork City</td>\n",
       "      <td>Portarlington</td>\n",
       "      <td>No Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where is D'Olier Street?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Exact Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D'Olier Street is named after whom?</td>\n",
       "      <td>A number of Huguenots served as mayors in Dubl...</td>\n",
       "      <td>a High Sheriff and one of the founders of the ...</td>\n",
       "      <td>High Sheriff</td>\n",
       "      <td>No Match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  Which English town had the largest refugee chu...   \n",
       "1  What Irish cities had Huguenot mayors in the 1...   \n",
       "2        French Church Street is in what Irish town?   \n",
       "3                           Where is D'Olier Street?   \n",
       "4                D'Olier Street is named after whom?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Other evidence of the Walloons and Huguenots i...   \n",
       "1  A number of Huguenots served as mayors in Dubl...   \n",
       "2  A number of Huguenots served as mayors in Dubl...   \n",
       "3  A number of Huguenots served as mayors in Dubl...   \n",
       "4  A number of Huguenots served as mayors in Dubl...   \n",
       "\n",
       "                                       actual_answer  \\\n",
       "0                                         Canterbury   \n",
       "1                Dublin, Cork, Youghal and Waterford   \n",
       "2                                          Cork City   \n",
       "3                                             Dublin   \n",
       "4  a High Sheriff and one of the founders of the ...   \n",
       "\n",
       "                      predicted_answer evaluation_criteria  \n",
       "0    Sandwich, Faversham and Maidstone            No Match  \n",
       "1  Dublin, Cork, Youghal and Waterford         Exact Match  \n",
       "2                        Portarlington            No Match  \n",
       "3                               Dublin         Exact Match  \n",
       "4                         High Sheriff            No Match  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is evaluation based on No Match, Exact Match and partial match. This type of evaluation can be tweeked to take business requirement and criteria into consideration. We can implement further logic on the outcome and create a formula that will give us one score. To be honest this logic that I used can be further improved as per the business criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Match              522\n",
       "Exact Match           254\n",
       "Low Partial Match     151\n",
       "High Partial Match     73\n",
       "Name: evaluation_criteria, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['evaluation_criteria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def get_metrics(actual_answer, predicted_answers):\n",
    "    accuracy = accuracy_score(actual_answer, predicted_answers)\n",
    "    precision = precision_score(actual_answer, predicted_answers, average='macro')\n",
    "    recall = recall_score(actual_answer, predicted_answers, average='macro')\n",
    "    f1 = f1_score(actual_answer, predicted_answers, average='macro')\n",
    "\n",
    "    results = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = get_metrics(actual_answer,pred_answer_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is evaluation based on metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.217,\n",
       " 'Precision': 0.11146521501682433,\n",
       " 'Recall': 0.1423510913799482,\n",
       " 'F1 Score': 0.11523753715762595}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
